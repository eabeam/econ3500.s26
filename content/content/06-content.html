---
title: Week 6 - Multiple Linear Regression
sitetitle: Week 6
summary: "EC200 - Week 6 Multiple Regression (CH6)"

date: "2022-02-08"
start_date: "2022-02-21"
end_date: "2022-02-25"

  
  # Academic page type (do not modify).
type: docs
menu:
  content:
    parent: Course content
    weight: 6
    
output:
  blogdown::html_page:
    toc: true

pdf: /slides/ch6-slides.pdf
thumb: /slides/ch6-slides.png



---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>

<div id="TOC">
<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#reading-guide">Reading Guide</a></li>
<li><a href="#slides">Slides</a></li>
<li><a href="#videos">Videos</a>
<ul>
<li><a href="#video-multiple-linear-regression"><span>Video: Multiple Linear Regression</span></a></li>
</ul></li>
<li><a href="#in-class-exercises">In-class exercises</a>
<ul>
<li><a href="#exercises">Exercises</a></li>
</ul></li>
<li><a href="#other-resources">Other resources</a></li>
</ul>
</div>

<div id="overview" class="section level2">
<h2>Overview</h2>
<p>Let’s model!</p>
<p>Now, we can build powerful models with heaps of dependent variables. Want to predict wages? Let’s control for education, for experience, for gender, for age, for age <em>squared</em> (yes!). YES. Only our degrees of freedom can hold us back.</p>
</div>
<div id="reading-guide" class="section level2">
<h2>Reading Guide</h2>
<div id="chapter-6-linear-regression-with-multiple-regressors" class="section level4">
<h4><strong>Chapter 6: Linear Regression with Multiple Regressors</strong></h4>
</div>
<div id="sw-6.1-omitted-variable-bias" class="section level4">
<h4><strong>SW 6.1</strong> Omitted Variable Bias</h4>
<p>A discussion that connects nicely with our previous discussion of the zero conditional mean discussion and causal inference.</p>
</div>
<div id="sw-6.2-the-multiple-regression-model" class="section level4">
<h4><strong>SW 6.2</strong> The Multiple Regression Model</h4>
<p>Hooray!</p>
</div>
<div id="sw-6.3-the-ols-estimator-in-multiple-regression" class="section level4">
<h4><strong>SW 6.3</strong> The OLS Estimator in Multiple Regression</h4>
<p>This section doesn’t get into derivation, and neither do we!</p>
</div>
<div id="sw-6.4-measures-of-fit-in-multiple-regression" class="section level4">
<h4><strong>SW 6.4</strong> Measures of Fit in Multiple Regression</h4>
<p>The only <em>new</em> thing here is a revised <span class="math inline">\(SER\)</span> forumla and the introduction of the Adjusted <span class="math inline">\(R^2\)</span>. Note that the lecture video also discusses the root mean standard error, <span class="math inline">\(RMSE\)</span>, which is a lot like the <span class="math inline">\(SER\)</span> except that it uses <span class="math inline">\(n\)</span> rather than degrees of freedom as a denominator.</p>
</div>
<div id="sw-6.5-the-least-squares-assumptions-in-multiple-regression" class="section level4">
<h4><strong>SW 6.5</strong> The Least Squares Assumptions in Multiple Regression</h4>
<p>Take the three from univariate regression and add … no multicollinearity. Sorted.</p>
</div>
<div id="sw-6.6-distribution-of-the-ols-estimators-in-multiple-regression" class="section level4">
<h4><strong>SW 6.6</strong> Distribution of the OLS Estimators in Multiple Regression</h4>
<p>Just the intuition, don’t worry about the appendix.</p>
</div>
<div id="sw-6.7-multicollinearity" class="section level4">
<h4><strong>SW 6.7</strong> Multicollinearity</h4>
<p>Make sure you understand the examples, but remember that in practice, any statistical package will fix perfect multicollinearity on its own. Imperfect multicollinearity, on the other hand, is something to think about when crafting your models.</p>
</div>
<div id="sw-6.8-conclusion" class="section level4">
<h4><strong>SW 6.8</strong> Conclusion</h4>
<p>Treat yourself.</p>
</div>
</div>
<div id="slides" class="section level2">
<h2>Slides</h2>
<p>{{% slides %}}</p>
</div>
<div id="videos" class="section level2">
<h2>Videos</h2>
<div id="video-multiple-linear-regression" class="section level3">
<h3><a href="https://youtu.be/XIrD0qD0TCs">Video: Multiple Linear Regression</a></h3>
<p>{{< youtube XIrD0qD0TCs >}}</p>
</div>
</div>
<div id="in-class-exercises" class="section level2">
<h2>In-class exercises</h2>
<p>Download PDF <a href="../practice/W6-01-in-class-exercise.pdf">here</a>, which contains regression output for questions (2) - (4)</p>
<div id="exercises" class="section level3">
<h3>Exercises</h3>
<p>Consider a dataset on earnings in the United States. We are interested
in the returns to education - how much an extra year of schooling “buys”
you in terms of weekly wages (...as of 1980). You’re also worried about
whether one’s education suffers from omitted variable bias.</p>
<ol style="list-style-type: decimal">
<li><p>You estimate two equations: <span class="math display">\[\begin{aligned}
\widehat{wage} &amp;= 146.95 + 60.21educ\\
\widehat{educ} &amp; = 5.84 + 0.075IQ\end{aligned}\]</span></p>
<p>Based on these results, is 60.21 an overestimate or underestimate of
the returns to education? How do you know?</p></li>
<li><p>You estimate another equation:
<span class="math inline">\(\widehat{wage} = -128.89 +42.06 educ + 5.14 IQ\)</span></p>
<p>What is the interpretation of the coefficient on <span class="math inline">\(educ\)</span>? What is the
interpretation of the constant?</p></li>
<li><p>Now, you control for experience and age and estimate the following
population regression model:</p>
<p><span class="math display">\[wage_i = \beta_0 + \beta_1 educ_i + \beta_2 IQ_i + \beta_3 exper_i + \beta_4 age_i + \beta_5 age_i^2 + u_i\]</span></p>
<p>A one-year increase in age is associated with what change in wages?
(mind the squared term)</p></li>
</ol>
<p><img src="../practice/w6-q1.png"></p>
<ol start="4" style="list-style-type: decimal">
<li><p>Finally, because you are worried about omitted variable bias, you
include father’s and mother’s education.</p>
<p><img src="../practice/w6-q2.png"></p>
<ol style="list-style-type: decimal">
<li><p>Why might parent’s education might directly affect wages?</p></li>
<li><p>Which other independent variables do you think parent’s
education might affect? Explain.</p></li>
<li><p>How did controlling for parent’s education affect the returns to
education? The returns to IQ?</p></li>
</ol></li>
</ol>
</div>
</div>
<div id="other-resources" class="section level2">
<h2>Other resources</h2>
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">
As requested, slower graphs! Also added a graph on collider bias, the webpage explanation helps there.<br><br>These graphs are intended to show what standard causal inference methods actually <em>do</em> to data, and how they work.<br><br>This is what controlling for a binary variable looks like: <a href="https://t.co/dTZxqY5JxA">pic.twitter.com/dTZxqY5JxA</a>
</p>
— Nick HK (<span class="citation">@nickchk</span>) <a href="https://twitter.com/nickchk/status/1068215492458905600?ref_src=twsrc%5Etfw">November 29, 2018</a>
</blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
